# CUDA_VISIBLE_DEVICES=0,1 python -m torch.distributed.launch --nproc_per_node=2 --master_port=51234 train.py --expe_name new_resnet_softmax_advbct --config-file ./configs/finetune/sub_model/vit_s.yaml NUM_GPUS 2 OUTPUT_DIR "output/vit_sub_model/vit-s indepedent" COMP_LOSS.TYPE 'independent'
# CUDA_VISIBLE_DEVICES=0,1 python -m torch.distributed.launch --nproc_per_node=2 --master_port=51234 train.py --expe_name new_resnet_softmax_advbct --config-file ./configs/finetune/sub_model/vit_s.yaml NUM_GPUS 2 OUTPUT_DIR "output/vit_sub_model/vit-s indepedent" COMP_LOSS.TYPE 'independent'

# timm-vit
# CUDA_VISIBLE_DEVICES=0,1 python -m torch.distributed.launch --nproc_per_node=2 --master_port=51634 train.py --expe_name new_resnet_softmax_advbct --config-file ./configs/finetune/sub_model/timm-vit.yaml NUM_GPUS 2 OUTPUT_DIR "output/vit_sub_model/our timm vit-t 0.00003 independent MODEL.PRETRAIN True" COMP_LOSS.TYPE 'independent' MODEL.PRETRAIN True
# CUDA_VISIBLE_DEVICES=0,1 python -m torch.distributed.launch --nproc_per_node=2 --master_port=52334 train.py --expe_name new_resnet_softmax_advbct --config-file ./configs/finetune/sub_model/timm-vit.yaml NUM_GPUS 2 OUTPUT_DIR "output/vit_sub_model/our timm vit-t 0.00005 independent MODEL.PRETRAIN True" COMP_LOSS.TYPE 'independent' MODEL.PRETRAIN True SOLVER.BASE_LR 0.00005

# CUDA_VISIBLE_DEVICES=0,1 python -m torch.distributed.launch --nproc_per_node=2 --master_port=52314 train.py --expe_name new_resnet_softmax_advbct --config-file ./configs/finetune/sub_model/timm-vit.yaml NUM_GPUS 2 OUTPUT_DIR "output/vit_sub_model/debug" COMP_LOSS.TYPE 'independent' MODEL.PRETRAIN True SUB_MODEL.GRAD_PROJ False SUB_MODEL.PROJ_W_M True BN_TRACK True
# CUDA_VISIBLE_DEVICES=0,1 python -m torch.distributed.launch --nproc_per_node=2 --master_port=52114 train.py --expe_name new_resnet_softmax_advbct --config-file ./configs/finetune/sub_model/timm-vit.yaml NUM_GPUS 2 OUTPUT_DIR "output/vit_sub_model/0.5 submodel cos sim proj bn track true with dropout sub model proj" COMP_LOSS.TYPE 'proj_with_cosine_sim' MODEL.PRETRAIN True SUB_MODEL.GRAD_PROJ True SUB_MODEL.PROJ_W_M True BN_TRACK True
# CUDA_VISIBLE_DEVICES=2,3 python -m torch.distributed.launch --nproc_per_node=2 --master_port=51314 train.py --expe_name new_resnet_softmax_advbct --config-file ./configs/finetune/sub_model/timm-vit.yaml NUM_GPUS 2 OUTPUT_DIR "output/vit_sub_model/vit-s 4 submodels" COMP_LOSS.TYPE 'proj_with_cosine_sim' MODEL.PRETRAIN True SUB_MODEL.GRAD_PROJ True SUB_MODEL.PROJ_W_M True BN_TRACK True SUB_MODEL.SPARSITY [0.2,0.4,0.6,0.8] DATA.BATCH_SIZE 64
# CUDA_VISIBLE_DEVICES=2,3 python -m torch.distributed.launch --nproc_per_node=2 --master_port=51314 train.py --expe_name new_resnet_softmax_advbct --config-file ./configs/finetune/sub_model/timm-vit.yaml NUM_GPUS 2 OUTPUT_DIR "output/vit_sub_model/vit-s 4 submodels" COMP_LOSS.TYPE 'independent' MODEL.PRETRAIN True SUB_MODEL.GRAD_PROJ False SUB_MODEL.PROJ_W_M False BN_TRACK True DATA.BATCH_SIZE 64
# CUDA_VISIBLE_DEVICES=2,3 python -m torch.distributed.launch --nproc_per_node=2 --master_port=52154 train.py --expe_name new_resnet_softmax_advbct --config-file ./configs/finetune/sub_model/timm-vit.yaml NUM_GPUS 2 OUTPUT_DIR "output/vit_sub_model/0.5 submodel cos sim proj bn track true with dropout" COMP_LOSS.TYPE 'proj_with_cosine_sim' MODEL.PRETRAIN True SUB_MODEL.GRAD_PROJ True SUB_MODEL.PROJ_W_M True BN_TRACK True

# test
# CUDA_VISIBLE_DEVICES=0,1 python -m torch.distributed.launch --nproc_per_node=2 --master_port=52714 train.py --expe_name new_resnet_softmax_advbct --config-file ./configs/finetune/sub_model/timm-vit.yaml NUM_GPUS 2 OUTPUT_DIR "output/vit_sub_model/test" COMP_LOSS.TYPE 'proj_with_cosine_sim' MODEL.PRETRAIN True BN_TRACK True SUB_MODEL.ONLY_TEST_PARENT False COMP_LOSS.ONLY_TEST True NEW_MODEL.WEIGHT_PATH './output/vit_sub_model/0.5 submodel cos sim proj bn track true with dropout/lmdb-gldv2/new_resnet_softmax_advbct/timm-vit/lr3e-05_wd0.001/run2/lmdb-gldv2_end2end_vit_tiny_patch16_224_in21k_epoch_013.pth'


# independent sub
# CUDA_VISIBLE_DEVICES=2,3 python -m torch.distributed.launch --nproc_per_node=2 --master_port=52355 train.py --expe_name new_resnet_softmax_advbct --config-file ./configs/finetune/sub_model/timm-vit.yaml NUM_GPUS 2 OUTPUT_DIR "output/vit_sub_model/vit-s 80%" COMP_LOSS.TYPE 'independent' MODEL.PRETRAIN True SUB_MODEL.GRAD_PROJ False SUB_MODEL.PROJ_W_M False BN_TRACK True  DATA.BATCH_SIZE 64 SUB_MODEL.USE_SWITCHNET True SNET.WIDTH_MULT_LIST [1.0] SUB_MODEL.PARENT_SPARSITY 1.0
# CUDA_VISIBLE_DEVICES=2,3 python -m torch.distributed.launch --nproc_per_node=2 --master_port=51155 train.py --expe_name new_resnet_softmax_advbct --config-file ./configs/finetune/sub_model/timm-vit.yaml NUM_GPUS 2 OUTPUT_DIR "output/vit_sub_model/vit-s 80%" COMP_LOSS.TYPE 'independent' MODEL.PRETRAIN True SUB_MODEL.GRAD_PROJ False SUB_MODEL.PROJ_W_M False BN_TRACK True  DATA.BATCH_SIZE 64 SUB_MODEL.USE_SWITCHNET True SNET.WIDTH_MULT_LIST [0.8944,1.0] SUB_MODEL.PARENT_SPARSITY 0.8944
# CUDA_VISIBLE_DEVICES=2,3 python -m torch.distributed.launch --nproc_per_node=2 --master_port=52355 train.py --expe_name new_resnet_softmax_advbct --config-file ./configs/finetune/sub_model/timm-vit.yaml NUM_GPUS 2 OUTPUT_DIR "output/vit_sub_model/vit-s 60%" COMP_LOSS.TYPE 'independent' MODEL.PRETRAIN True SUB_MODEL.GRAD_PROJ False SUB_MODEL.PROJ_W_M False BN_TRACK True  DATA.BATCH_SIZE 64 SUB_MODEL.USE_SWITCHNET True SNET.WIDTH_MULT_LIST [0.7746,1.0] SUB_MODEL.PARENT_SPARSITY 0.7746
# CUDA_VISIBLE_DEVICES=2,3 python -m torch.distributed.launch --nproc_per_node=2 --master_port=52355 train.py --expe_name new_resnet_softmax_advbct --config-file ./configs/finetune/sub_model/timm-vit.yaml NUM_GPUS 2 OUTPUT_DIR "output/vit_sub_model/vit-s 40%" COMP_LOSS.TYPE 'independent' MODEL.PRETRAIN True SUB_MODEL.GRAD_PROJ False SUB_MODEL.PROJ_W_M False BN_TRACK True  DATA.BATCH_SIZE 64 SUB_MODEL.USE_SWITCHNET True SNET.WIDTH_MULT_LIST [0.6325,1.0] SUB_MODEL.PARENT_SPARSITY 0.6325
# CUDA_VISIBLE_DEVICES=2,3 python -m torch.distributed.launch --nproc_per_node=2 --master_port=52355 train.py --expe_name new_resnet_softmax_advbct --config-file ./configs/finetune/sub_model/timm-vit.yaml NUM_GPUS 2 OUTPUT_DIR "output/vit_sub_model/vit-s 20%" COMP_LOSS.TYPE 'independent' MODEL.PRETRAIN True SUB_MODEL.GRAD_PROJ False SUB_MODEL.PROJ_W_M False BN_TRACK True  DATA.BATCH_SIZE 64 SUB_MODEL.USE_SWITCHNET True SNET.WIDTH_MULT_LIST [0.4472,1.0] SUB_MODEL.PARENT_SPARSITY 0.4472

# CUDA_VISIBLE_DEVICES=2,3 python -m torch.distributed.launch --nproc_per_node=2 --master_port=51155 train.py --expe_name new_resnet_softmax_advbct --config-file ./configs/finetune/sub_model/timm-vit.yaml NUM_GPUS 2 OUTPUT_DIR "output/vit_sub_model/vit-s 95%" COMP_LOSS.TYPE 'independent' MODEL.PRETRAIN True SUB_MODEL.GRAD_PROJ False SUB_MODEL.PROJ_W_M False BN_TRACK True  DATA.BATCH_SIZE 64 SUB_MODEL.USE_SWITCHNET True SNET.WIDTH_MULT_LIST [0.9746,1.0] SUB_MODEL.PARENT_SPARSITY 0.9746



# CUDA_VISIBLE_DEVICES=2,3 python -m torch.distributed.launch --nproc_per_node=2 --master_port=51355 train.py --expe_name new_resnet_softmax_advbct --config-file ./configs/finetune/sub_model/timm-vit.yaml NUM_GPUS 2 OUTPUT_DIR "output/vit_sub_model/vit-s 80%" COMP_LOSS.TYPE 'independent' MODEL.PRETRAIN True SUB_MODEL.GRAD_PROJ False SUB_MODEL.PROJ_W_M False BN_TRACK True  DATA.BATCH_SIZE 64 SUB_MODEL.USE_SWITCHNET False SUB_MODEL.SPARSITY [0.2] SUB_MODEL.PARENT_SPARSITY 0.2


# SFSC
CUDA_VISIBLE_DEVICES=2,3 python -m torch.distributed.launch --nproc_per_node=2 --master_port=35184 train.py --expe_name new_resnet_softmax_advbct --config-file ./configs/finetune/sub_model/timm-vit.yaml NUM_GPUS 2 OUTPUT_DIR "output/vit_sub_model/sfsc bct-s loss/" SUB_MODEL.USE_SWITCHNET True COMP_LOSS.TYPE 'SFSC' BN_TRACK True DATA.BATCH_SIZE 64 SNET.WIDTH_MULT_LIST [0.8944,0.7746,0.6325,0.4472,1.0] SUB_MODEL.PARENT_SPARSITY 1.0 SNET.USE_SFSC_LOSS False SUB_MODEL.SPARSITY [0.2,0.4,0.6,0.8] SUB_MODEL.GRAD_PROJ True BN_TRACK True MODEL.PRETRAIN True
